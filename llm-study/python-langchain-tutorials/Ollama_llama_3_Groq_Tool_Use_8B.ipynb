{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlr1JMrPfB4WAT1ZxKqXrK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ningxia202109/llm-learn/blob/main/python-langchain-tutorials/Ollama_llama_3_Groq_Tool_Use_8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**llama-3-Groq-Tool-Use-8B on local Ollama**\n",
        "\n",
        "References:\n",
        "\n",
        "1. https://ollama.com/library/llama3-groq-tool-use:8b\n",
        "2. https://www.youtube.com/watch?v=oCCxEvrs5PU\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WXPdzI8Ad_3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZxM3Qbed0d6"
      },
      "outputs": [],
      "source": [
        "# Ollama on T4 GPU\n",
        "%%capture --no-stderr\n",
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
        "!sudo apt-get update && sudo apt-get install -y cuda-drivers\n",
        "\n",
        "import os\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "os.environ.update({'OLLAMA_HOST': '0.0.0.0'})\n",
        "\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "\n",
        "    p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in p.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com \" in l:\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "            print(\"running ollama server\\n\\n\", l[l.find(\"http\"):], end='')\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(11434,)).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME=\"llama3-groq-tool-use:8b\"\n",
        "!ollama serve > ollama-server.log 2>&1 &\n",
        "!ollama run llama3-groq-tool-use:8b > llama3-groq-tool-use-8b.log 2>&1 &\n",
        "#!sleep 120\n",
        "# Wait for AI MODEL\n",
        "!while ! ollama list | grep -q \"$MODEL_NAME\"; do \\\n",
        "  echo \"Waiting for $MODEL_NAME to become available...\"; \\\n",
        "  sleep 10; \\\n",
        "done\n",
        "!echo \"$MODEL_NAME is now available.\"\n",
        "!ollama list\n",
        "!ollama --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMsbPlSgGLv",
        "outputId": "91ed84fd-fc49-435c-9cb9-234657509aae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "running ollama server\n",
            "\n",
            " https://naked-reno-isolated-copyrights.trycloudflare.com                                  |\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "Waiting for llama3-groq-tool-use:8b to become available...\n",
            "llama3-groq-tool-use:8b is now available.\n",
            "NAME                   \tID          \tSIZE  \tMODIFIED      \n",
            "llama3-groq-tool-use:8b\t55065f5d86c6\t4.7 GB\t4 seconds ago\t\n",
            "ollama version is 0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U -q langchain langchain_community langchain-openai"
      ],
      "metadata": {
        "id": "PMp8iIpth-J3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "ollama = ChatOpenAI(\n",
        "    api_key=\"ollama\",\n",
        "    model=\"llama3-groq-tool-use:8b\",\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        ")\n",
        "\n",
        "# Using Language Models\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Chinese\"),\n",
        "    HumanMessage(content=\"Today is a good day\"),\n",
        "]\n",
        "\n",
        "# Invoke the model to generate responses\n",
        "response = ollama.invoke(messages)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNNQ-0nFgwPT",
        "outputId": "04de752b-c5c4-47bd-d827-7f12fe41ad9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='(Ào kāi jīn rì hěn hǎo)' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 27, 'total_tokens': 45}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-41322347-50b3-49d1-ba52-620fe1d4de03-0' usage_metadata={'input_tokens': 27, 'output_tokens': 18, 'total_tokens': 45}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st Case - 使用Tool-Use 计算数学表达式**"
      ],
      "metadata": {
        "id": "t3_5ANQkgVLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "ollama_client = OpenAI(\n",
        "    base_url = 'http://localhost:11434/v1',\n",
        "    api_key='ollama', # required, but unused\n",
        ")\n",
        "\n",
        "# 导入所需的库\n",
        "# from groq import Groq  # 导入Groq API客户端\n",
        "import json  # 用于JSON数据处理\n",
        "import os  # 用于环境变量操作\n",
        "import pprint\n",
        "\n",
        "def calculate(expression):\n",
        "    \"\"\"计算数学表达式\"\"\"\n",
        "    try:\n",
        "        # 使用eval函数评估表达式\n",
        "        result = eval(expression)\n",
        "        # 返回JSON格式的结果\n",
        "        return json.dumps({\"result\": result})\n",
        "    except:\n",
        "        # 如果计算出错，返回错误信息\n",
        "        return json.dumps({\"error\": \"Invalid expression\"})\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    # 定义对话的消息列表\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"你是一个计算器助手。使用计算函数执行数学运算并提供结果.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # 定义可用的工具（函数）\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"calculate\",\n",
        "                \"description\": \"计算数学表达式\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"expression\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"要评估的数学表达式\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"expression\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print('第一次信息输出 \\n')\n",
        "    print(messages)\n",
        "    print('\\n')\n",
        "\n",
        "    # 发送第一次请求到Groq API\n",
        "\n",
        "    # 作用和目的：\n",
        "    # 初始化对话：将用户的问题发送给 AI 模型。\n",
        "    # 提供工具信息：告诉模型可以使用哪些工具（在这里是 calculate 函数）。\n",
        "    # 获取模型的初步响应：模型可能会直接回答，或者决定使用提供的工具。\n",
        "\n",
        "    # 特点：\n",
        "    # 包含了初始的对话历史（系统提示和用户问题）。\n",
        "    # 提供了 tools 参数，定义了可用的函数。\n",
        "    # 使用 tool_choice=\"auto\"，允许模型自主决定是否使用工具。\n",
        "    response = ollama_client.chat.completions.create(\n",
        "        model=\"llama3-groq-tool-use:8b\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=True,\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    print('\\n')\n",
        "    print('输出response \\n')\n",
        "    print(response)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "    # 获取响应消息和工具调用\n",
        "    response_message = response.choices[0].message\n",
        "    print('\\n')\n",
        "    print('第一次响应输出 \\n')\n",
        "    print(response_message)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "    tool_calls = response_message.tool_calls\n",
        "    print('输出tool_calls信息: \\n')\n",
        "    pprint.pprint(tool_calls)\n",
        "    print('\\n')\n",
        "\n",
        "    # 如果有工具调用\n",
        "    if tool_calls:\n",
        "        # 定义可用的函数字典\n",
        "        available_functions = {\n",
        "            \"calculate\": calculate,\n",
        "        }\n",
        "        # 将响应消息添加到对话历史\n",
        "        messages.append(response_message)\n",
        "\n",
        "        # 处理每个工具调用\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            # 解析函数参数\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            # 调用函数并获取响应\n",
        "            function_response = function_to_call(\n",
        "                expression=function_args.get(\"expression\")\n",
        "            )\n",
        "            print('\\n输出function_response '+function_response +'\\n')\n",
        "            # 将函数调用结果添加到对话历史\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print('第二次信息输出 \\n')\n",
        "        print(messages)\n",
        "        print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "        # 发送第二次请求到Groq API，包含函数调用结果\n",
        "\n",
        "        # 作用和目的：\n",
        "        # 处理工具调用的结果：将计算结果反馈给模型。\n",
        "        # 获取最终响应：让模型基于计算结果生成人类可读的回答。\n",
        "\n",
        "        # 特点：\n",
        "        # 包含了更新后的对话历史，包括第一次响应和工具调用的结果。\n",
        "        # 没有提供 tools 参数，因为此时不需要再次使用工具。\n",
        "        # 目的是获取最终的、格式化的回答。\n",
        "        second_response = ollama_client.chat.completions.create(\n",
        "            model=\"llama3-groq-tool-use:8b\",\n",
        "            messages=messages\n",
        "        )\n",
        "        # 返回最终响应内容\n",
        "        return second_response.choices[0].message.content\n",
        "\n",
        "# 定义用户提示\n",
        "user_prompt = \"计算25.6602988 * 4/0.259484 + 5.69560456 -398.11287180等于多少?这个数字有什么特殊意义吗?用中文回答.\"\n",
        "\n",
        "# user_prompt = \"1+1 等于多少?\"\n",
        "\n",
        "# 运行对话并打印结果\n",
        "print('第二次响应输出 \\n'+run_conversation(user_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BAiAsgtgYlL",
        "outputId": "7a006dcd-9096-4b97-e3f0-1a86431ff478"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一次信息输出 \n",
            "\n",
            "[{'role': 'system', 'content': '你是一个计算器助手。使用计算函数执行数学运算并提供结果.'}, {'role': 'user', 'content': '计算25.6602988 * 4/0.259484 + 5.69560456 -398.11287180等于多少?这个数字有什么特殊意义吗?用中文回答.'}]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "输出response \n",
            "\n",
            "ChatCompletion(id='chatcmpl-869', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_a9rgg51l', function=Function(arguments='{\"expression\":\"25.6602988 * 4/0.259484 + 5.69560456 -398.11287180\"}', name='calculate'), type='function')]))], created=1721617247, model='llama3-groq-tool-use:8b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=50, prompt_tokens=207, total_tokens=257))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "第一次响应输出 \n",
            "\n",
            "ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_a9rgg51l', function=Function(arguments='{\"expression\":\"25.6602988 * 4/0.259484 + 5.69560456 -398.11287180\"}', name='calculate'), type='function')])\n",
            "\n",
            "\n",
            "输出tool_calls信息: \n",
            "\n",
            "[ChatCompletionMessageToolCall(id='call_a9rgg51l', function=Function(arguments='{\"expression\":\"25.6602988 * 4/0.259484 + 5.69560456 -398.11287180\"}', name='calculate'), type='function')]\n",
            "\n",
            "\n",
            "\n",
            "输出function_response {\"result\": 3.1415926511686507}\n",
            "\n",
            "第二次信息输出 \n",
            "\n",
            "[{'role': 'system', 'content': '你是一个计算器助手。使用计算函数执行数学运算并提供结果.'}, {'role': 'user', 'content': '计算25.6602988 * 4/0.259484 + 5.69560456 -398.11287180等于多少?这个数字有什么特殊意义吗?用中文回答.'}, ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_a9rgg51l', function=Function(arguments='{\"expression\":\"25.6602988 * 4/0.259484 + 5.69560456 -398.11287180\"}', name='calculate'), type='function')]), {'tool_call_id': 'call_a9rgg51l', 'role': 'tool', 'name': 'calculate', 'content': '{\"result\": 3.1415926511686507}'}]\n",
            "\n",
            "\n",
            "第二次响应输出 \n",
            "计算结果是 3.14159265。这个结果没有特别的意义，可能是在科学计算中使用到的某个常见公式或数字。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**不使用Tool-Use，直接调用API**"
      ],
      "metadata": {
        "id": "o-J07O6zls1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_conversation(user_prompt):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"你是一个计算器助手。你需要理解用户的数学问题，进行计算，并提供详细的步骤和最终结果。请确保你的计算是准确的。\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = ollama_client.chat.completions.create(\n",
        "        model=\"llama3-groq-tool-use:8b\",\n",
        "        messages=messages,\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "user_prompt = \"计算25.6602988 * 4/0.259484 + 5.69560456689 -398.112871804等于多少?这个数字有什么特殊意义吗?用中文回答.\"\n",
        "\n",
        "print(run_conversation(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9X5Ou5NluH5",
        "outputId": "08c67bc7-e23e-471d-a5ae-cb9fe2946215"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The calculation you provided is quite complex. To ensure accuracy, I'll break it down step by step:\n",
            "\n",
            "1. Calculate 25.6602988 * 4/0.259484 = 390.1234\n",
            "2. Add 5.69560456689 to the result: 390.1234 + 5.69560456689 = 395.8190\n",
            "3. Subtract 398.112871804 from the result: 395.8190 - 398.112871804 ≈ -2.2938\n",
            "\n",
            "The final calculation is approximately -2.2938.\n",
            "\n",
            "This number doesn't have any specific meaning without more context, but it's a result of a complex mathematical operation involving multiple calculations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2nd Case - Text2SQL**"
      ],
      "metadata": {
        "id": "w2BBD37cmAlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sqlite3\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# 连接到SQLite数据库（如果不存在则创建）\n",
        "conn = sqlite3.connect('demo_users.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# 创建用户表\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS users (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    age INTEGER,\n",
        "    email TEXT UNIQUE,\n",
        "    registration_date DATE,\n",
        "    last_login DATETIME\n",
        ")\n",
        "''')\n",
        "\n",
        "# 生成示例数据\n",
        "names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\", \"Frank\", \"Grace\", \"Henry\", \"Ivy\", \"Jack\"]\n",
        "domains = [\"gmail.com\", \"yahoo.com\", \"hotmail.com\", \"example.com\"]\n",
        "\n",
        "for i in range(50):  # 创建50个用户记录\n",
        "    name = random.choice(names)\n",
        "    age = random.randint(18, 70)\n",
        "    email = f\"{name.lower()}{random.randint(1, 100)}@{random.choice(domains)}\"\n",
        "    registration_date = datetime.now() - timedelta(days=random.randint(1, 1000))\n",
        "    last_login = registration_date + timedelta(days=random.randint(1, 500))\n",
        "    cursor.execute('''\n",
        "    INSERT INTO users (name, age, email, registration_date, last_login)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (name, age, email, registration_date.date(), last_login))\n",
        "\n",
        "# 提交更改并关闭连接\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Demo database 'demo_users.db' created successfully with sample data.\")\n",
        "\n",
        "# 函数用于显示表格内容\n",
        "def display_table_contents():\n",
        "    conn = sqlite3.connect('demo_users.db')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM users LIMIT 5\")\n",
        "    rows = cursor.fetchall()\n",
        "\n",
        "    print(\"\\nSample data from the users table:\")\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "display_table_contents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sq3MiFhmQU5",
        "outputId": "269b805d-1cfd-48e2-b91b-07b3a5da5b8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo database 'demo_users.db' created successfully with sample data.\n",
            "\n",
            "Sample data from the users table:\n",
            "(1, 'Henry', 46, 'henry16@yahoo.com', '2022-08-08', '2022-09-06 03:01:25.097762')\n",
            "(2, 'Henry', 62, 'henry84@example.com', '2022-02-18', '2022-10-04 03:01:25.097983')\n",
            "(3, 'Frank', 41, 'frank20@example.com', '2023-02-19', '2023-12-28 03:01:25.098016')\n",
            "(4, 'Henry', 42, 'henry89@hotmail.com', '2022-03-09', '2022-10-12 03:01:25.098039')\n",
            "(5, 'Henry', 69, 'henry46@hotmail.com', '2023-10-18', '2023-11-30 03:01:25.098061')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# 数据库连接函数\n",
        "def get_db_connection():\n",
        "    \"\"\"创建并返回到SQLite数据库的连接\"\"\"\n",
        "    conn = sqlite3.connect('demo_users.db')\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    return conn\n",
        "\n",
        "def execute_sql(sql_query):\n",
        "    \"\"\"执行SQL查询并返回结果\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        results = [dict(row) for row in cursor.fetchall()]\n",
        "        return results\n",
        "    except sqlite3.Error as e:\n",
        "        return f\"数据库错误: {e}\"\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "def generate_sql(table_info, conditions, select_fields=\"*\"):\n",
        "    \"\"\"\n",
        "    生成SQL查询\n",
        "    :param table_info: 表信息\n",
        "    :param conditions: WHERE子句的条件\n",
        "    :param select_fields: 要选择的字段，默认为所有字段\n",
        "    :return: 生成的SQL查询字符串\n",
        "    \"\"\"\n",
        "    return f\"SELECT {select_fields} FROM users WHERE {conditions}\"\n",
        "\n",
        "def format_results(results, fields=None):\n",
        "    \"\"\"\n",
        "    格式化查询结果\n",
        "    :param results: 查询返回的结果列表\n",
        "    :param fields: 要显示的字段列表，如果为None则显示所有字段\n",
        "    :return: 格式化后的结果字符串\n",
        "    \"\"\"\n",
        "    if isinstance(results, str):  # 如果结果是错误消息\n",
        "        return results\n",
        "\n",
        "    if not results:\n",
        "        return \"没有找到匹配的记录。\"\n",
        "\n",
        "    if fields:\n",
        "        formatted = [\", \".join(str(row.get(field, \"N/A\")) for field in fields) for row in results]\n",
        "    else:\n",
        "        formatted = [json.dumps(row, ensure_ascii=False, indent=2) for row in results]\n",
        "\n",
        "    return \"\\n\".join(formatted)\n",
        "\n",
        "def ollama_query(messages, tools):\n",
        "    return ollama_client.chat.completions.create(\n",
        "            model=\"llama3-groq-tool-use:8b\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=True,\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "def gpt_4o_mini_query(messages, tools):\n",
        "    gpt_client = OpenAI()\n",
        "    return gpt_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "def run_text2sql_conversation(user_prompt):\n",
        "    \"\"\"\n",
        "    运行text2sql对话\n",
        "    :param user_prompt: 用户输入的查询\n",
        "    :return: 查询结果\n",
        "    \"\"\"\n",
        "    table_info = \"users(id INTEGER, name TEXT, age INTEGER, email TEXT, registration_date DATE, last_login DATETIME)\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"你是一个SQL助手。使用generate_sql函数根据用户请求创建SQL查询。可用的表: {table_info}。准确理解用户需求，包括他们想要查询的具体字段。\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"generate_sql\",\n",
        "                \"description\": \"根据用户请求生成SQL查询\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"table_info\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"表结构信息\",\n",
        "                        },\n",
        "                        \"conditions\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"WHERE子句的具体查询条件\",\n",
        "                        },\n",
        "                        \"select_fields\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"要选择的字段，用逗号分隔\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"table_info\", \"conditions\", \"select_fields\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "    try:\n",
        "        response = ollama_query(messages, tools)\n",
        "        # response = gpt_4o_mini_query(messages, tools)\n",
        "        print(response)\n",
        "        assistant_message = response.choices[0].message\n",
        "        if assistant_message.tool_calls:\n",
        "            for tool_call in assistant_message.tool_calls:\n",
        "                if tool_call.function.name == \"generate_sql\":\n",
        "                    function_args = json.loads(tool_call.function.arguments)\n",
        "                    sql_query = generate_sql(\n",
        "                        function_args[\"table_info\"],\n",
        "                        function_args[\"conditions\"],\n",
        "                        function_args[\"select_fields\"]\n",
        "                    )\n",
        "                    results = execute_sql(sql_query)\n",
        "                    formatted_results = format_results(results, function_args[\"select_fields\"].split(\", \") if function_args[\"select_fields\"] != \"*\" else None)\n",
        "                    return f\"生成的SQL查询: {sql_query}\\n\\n结果:\\n{formatted_results}\"\n",
        "\n",
        "        return \"无法生成SQL查询。请尝试重新表述您的问题。\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"发生错误: {str(e)}\"\n",
        "\n",
        "\n",
        "result = run_text2sql_conversation(\"Query Ivy age\")\n",
        "print(result)\n",
        "\n",
        "# 主程序\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"欢迎使用Text2SQL系统！\")\n",
        "#     print(\"您可以用自然语言询问有关用户表的问题。\")\n",
        "#     print(\"输入'quit'退出程序。\")\n",
        "\n",
        "#     while True:\n",
        "#         user_input = input(\"\\n请输入您的查询 (或 'quit' 退出): \")\n",
        "#         if user_input.lower() == 'quit':\n",
        "#             print(\"谢谢使用，再见！\")\n",
        "#             break\n",
        "\n",
        "#         result = run_text2sql_conversation(user_input)\n",
        "#         print(\"\\n\" + \"=\"*50)\n",
        "#         print(result)\n",
        "#         print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddlpKJ8Emcip",
        "outputId": "e2c5969e-0944-4534-b56f-791869c03df4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-56', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_g1ro8h87', function=Function(arguments='{\"conditions\":\"name = \\'Ivy\\'\",\"select_fields\":\"age\",\"table_info\":\"users(id INTEGER, name TEXT, age INTEGER, email TEXT, registration_date DATE, last_login DATETIME)\"}', name='generate_sql'), type='function')]))], created=1721617872, model='llama3-groq-tool-use:8b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=65, prompt_tokens=248, total_tokens=313))\n",
            "生成的SQL查询: SELECT age FROM users WHERE name = 'Ivy'\n",
            "\n",
            "结果:\n",
            "30\n",
            "28\n",
            "34\n",
            "65\n",
            "49\n",
            "20\n"
          ]
        }
      ]
    }
  ]
}