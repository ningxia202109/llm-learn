{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPymwaw2tPrdGTug3O2f/0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ningxia202109/llm-learn/blob/main/GraphRAG/GraphRAG_Ollama_llama3_1_8b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GraphRAG_Ollama_llama3-1_8b**\n",
        "\n",
        "\n",
        "https://github.com/TheAiSingularity/graphrag-local-ollama\n",
        "\n",
        "*Note*: Not succeed indexing\n"
      ],
      "metadata": {
        "id": "gCSHeSZlBBtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6eLPtin9qD9S"
      },
      "outputs": [],
      "source": [
        "# Ollama on T4 GPU\n",
        "# Install Ollama and GPU Package\n",
        "%%capture --no-stderr\n",
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
        "!sudo apt-get update && sudo apt-get install -y cuda-drivers\n",
        "\n",
        "import os\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "os.environ.update({'OLLAMA_HOST': '0.0.0.0'})\n",
        "\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "\n",
        "    p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in p.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com \" in l:\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "            print(\"running ollama server\\n\\n\", l[l.find(\"http\"):], end='')\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(11434,)).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Start Ollama\n",
        "LLM_MODEL=\"llama3.1\"\n",
        "!ollama serve > ollama-server.log 2>&1 &\n",
        "!ollama --version\n",
        "\n",
        "# Run LLM model\n",
        "# !ollama run llama3.1:8b > llama3-1-8b.log 2>&1 &\n",
        "# # Wait for AI MODEL\n",
        "# !while ! ollama list | grep -q \"$LLM_MODEL\"; do \\\n",
        "#   echo \"Waiting for $LLM_MODEL to become available...\"; \\\n",
        "#   sleep 15; \\\n",
        "# done\n",
        "# !echo \"$LLM_MODEL is now available.\"\n",
        "!ollama pull $LLM_MODEL\n",
        "\n",
        "# Pull Ollama embedding\n",
        "EMBEDDING_MODEL=\"nomic-embed-text\"\n",
        "!ollama pull $EMBEDDING_MODEL"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JaEnLuVGq2za"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List Ollama models\n",
        "!ollama list\n",
        "!curl http://localhost:11434/v1/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C00USEgo7JEo",
        "outputId": "8d699b77-ff49-4e4e-ff80-4d27f164831a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                   \tID          \tSIZE  \tMODIFIED       \n",
            "llama3.1:latest        \t62757c860e01\t4.7 GB\t18 seconds ago\t\n",
            "nomic-embed-text:latest\t0a109f422b47\t274 MB\t17 seconds ago\t\n",
            "llama3.1:8b            \t62757c860e01\t4.7 GB\t27 minutes ago\t\n",
            "{\"object\":\"list\",\"data\":[{\"id\":\"llama3.1:latest\",\"object\":\"model\",\"created\":1722914982,\"owned_by\":\"library\"},{\"id\":\"nomic-embed-text:latest\",\"object\":\"model\",\"created\":1722914982,\"owned_by\":\"library\"},{\"id\":\"llama3.1:8b\",\"object\":\"model\",\"created\":1722913361,\"owned_by\":\"library\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages of GraphRAG\n",
        "%%capture --no-stderr\n",
        "!pip install graphrag"
      ],
      "metadata": {
        "id": "pGGPIhEarvGw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intial GraphRAG folder\n",
        "%cd /content\n",
        "!mkdir -p ./ragtest/input\n",
        "!python -m graphrag.index --init --root ./ragtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fq58cAo7slr8",
        "outputId": "4d6978fe-1bd7-405f-f47d-d6a1d4053dbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "2024-08-06 03:04:09.282129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 03:04:09.573576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 03:04:09.650993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 03:04:12.818719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2KInitializing project at .\u001b[35m/\u001b[0m\u001b[95mragtest\u001b[0m\n",
            "⠋ GraphRAG Indexer "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurea GraphRAG\n",
        "%%writefile ./ragtest/settings.yaml\n",
        "\n",
        "encoding_model: cl100k_base\n",
        "skip_workflows: []\n",
        "llm:\n",
        "  api_key: ollama\n",
        "  type: openai_chat # or azure_openai_chat\n",
        "  model:  llama3.1\n",
        "  model_supports_json: true # recommended if this is available for your model.\n",
        "  # max_tokens: 3000\n",
        "  # request_timeout: 180.0\n",
        "  api_base: http://localhost:11434/v1\n",
        "  # api_version: 2024-02-15-preview\n",
        "  # organization:\n",
        "  # deployment_name:\n",
        "  # tokens_per_minute: 6000 # set a leaky bucket throttle\n",
        "  # requests_per_minute: 2 # set a leaky bucket throttle\n",
        "  # max_retries: 3\n",
        "  # max_retry_wait: 10.0\n",
        "  # sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times\n",
        "  concurrent_requests: 1 # the number of parallel inflight requests that may be made\n",
        "\n",
        "parallelization:\n",
        "  stagger: 0.3\n",
        "  # num_threads: 50 # the number of threads to use for parallel processing\n",
        "\n",
        "async_mode: threaded # or asyncio\n",
        "\n",
        "embeddings:\n",
        "  ## parallelization: override the global parallelization settings for embeddings\n",
        "  async_mode: threaded # or asyncio\n",
        "  llm:\n",
        "    api_key: ollama\n",
        "    type: openai_embedding # or azure_openai_embedding\n",
        "    model:  nomic-embed-text\n",
        "    api_base: http://localhost:11434/api\n",
        "    # api_version: 2024-02-15-preview\n",
        "    # organization:\n",
        "    # deployment_name:\n",
        "    # tokens_per_minute: 150_000 # set a leaky bucket throttle\n",
        "    # requests_per_minute: 10_000 # set a leaky bucket throttle\n",
        "    # max_retries: 10\n",
        "    # max_retry_wait: 10.0\n",
        "    # sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times\n",
        "    concurrent_requests: 1 # the number of parallel inflight requests that may be made\n",
        "    # batch_size: 16 # the number of documents to send in a single request\n",
        "    # batch_max_tokens: 8191 # the maximum number of tokens to send in a single request\n",
        "    # target: required # or optional\n",
        "\n",
        "\n",
        "\n",
        "chunks:\n",
        "  size: 300\n",
        "  overlap: 100\n",
        "  group_by_columns: [id] # by default, we don't allow chunks to cross documents\n",
        "\n",
        "input:\n",
        "  type: file # or blob\n",
        "  file_type: text # or csv\n",
        "  base_dir: \"input\"\n",
        "  file_encoding: utf-8\n",
        "  file_pattern: .*\\.txt$\n",
        "\n",
        "cache:\n",
        "  type: file # or blob\n",
        "  base_dir: \"cache\"\n",
        "  # connection_string:\n",
        "  # container_name:\n",
        "\n",
        "storage:\n",
        "  type: file # or blob\n",
        "  base_dir: \"output/${timestamp}/artifacts\"\n",
        "  # connection_string:\n",
        "  # container_name:\n",
        "\n",
        "reporting:\n",
        "  type: file # or console, blob\n",
        "  base_dir: \"output/${timestamp}/reports\"\n",
        "  # connection_string:\n",
        "  # container_name:\n",
        "\n",
        "entity_extraction:\n",
        "  ## llm: override the global llm settings for this task\n",
        "  ## parallelization: override the global parallelization settings for this task\n",
        "  ## async_mode: override the global async_mode settings for this task\n",
        "  prompt: \"prompts/entity_extraction.txt\"\n",
        "  entity_types: [organization,person,geo,event]\n",
        "  max_gleanings: 0\n",
        "\n",
        "summarize_descriptions:\n",
        "  ## llm: override the global llm settings for this task\n",
        "  ## parallelization: override the global parallelization settings for this task\n",
        "  ## async_mode: override the global async_mode settings for this task\n",
        "  prompt: \"prompts/summarize_descriptions.txt\"\n",
        "  max_length: 500\n",
        "\n",
        "claim_extraction:\n",
        "  ## llm: override the global llm settings for this task\n",
        "  ## parallelization: override the global parallelization settings for this task\n",
        "  ## async_mode: override the global async_mode settings for this task\n",
        "  # enabled: true\n",
        "  prompt: \"prompts/claim_extraction.txt\"\n",
        "  description: \"Any claims or facts that could be relevant to information discovery.\"\n",
        "  max_gleanings: 0\n",
        "\n",
        "community_report:\n",
        "  ## llm: override the global llm settings for this task\n",
        "  ## parallelization: override the global parallelization settings for this task\n",
        "  ## async_mode: override the global async_mode settings for this task\n",
        "  prompt: \"prompts/community_report.txt\"\n",
        "  max_length: 2000\n",
        "  max_input_length: 8000\n",
        "\n",
        "cluster_graph:\n",
        "  max_cluster_size: 10\n",
        "\n",
        "embed_graph:\n",
        "  enabled: false # if true, will generate node2vec embeddings for nodes\n",
        "  # num_walks: 10\n",
        "  # walk_length: 40\n",
        "  # window_size: 2\n",
        "  # iterations: 3\n",
        "  # random_seed: 597832\n",
        "\n",
        "umap:\n",
        "  enabled: false # if true, will generate UMAP embeddings for nodes\n",
        "\n",
        "snapshots:\n",
        "  graphml: true\n",
        "  raw_entities: true\n",
        "  top_level_nodes: true\n",
        "\n",
        "local_search:\n",
        "  # text_unit_prop: 0.5\n",
        "  # community_prop: 0.1\n",
        "  # conversation_history_max_turns: 5\n",
        "  # top_k_mapped_entities: 10\n",
        "  # top_k_relationships: 10\n",
        "  # max_tokens: 12000\n",
        "\n",
        "global_search:\n",
        "  # max_tokens: 12000\n",
        "  # data_max_tokens: 12000\n",
        "  # map_max_tokens: 1000\n",
        "  # reduce_max_tokens: 2000\n",
        "  # concurrency: 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjwIIndSs6Hu",
        "outputId": "9fff79cb-0e85-4757-9541-32381915203f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./ragtest/settings.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "%%writefile /content/ragtest/input/sample.txt\n",
        "\n",
        "MARLEY'S GHOST\n",
        "\n",
        "Marley was dead, to begin with. There is no doubt whatever about that.\n",
        "The register of his burial was signed by the clergyman, the clerk, the\n",
        "undertaker, and the chief mourner. Scrooge signed it. And Scrooge's name\n",
        "was good upon 'Change for anything he chose to put his hand to. Old\n",
        "Marley was as dead as a door-nail."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvpQBzOCwNSe",
        "outputId": "499f2718-6216-4a95-91af-c89bc3c85495"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ragtest/input/sample.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Environment Variables\n",
        "from google.colab import userdata\n",
        "import os\n",
        "# GROQ_API_KEY = '' # @param {type:\"string\"}\n",
        "# HUGGING_FACE_TOKEN = '' # @param {type:\"string\"}\n",
        "\n",
        "# Get your API Key from https://console.groq.com/keys\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "os.environ['GRAPHRAG_API_KEY'] = 'DUMMY_KEY'\n",
        "# If gated LLM\n",
        "# os.environ['HUGGING_FACE_TOKEN'] = HUGGING_FACE_TOKEN\n",
        "\n",
        "if len(os.getenv(\"GROQ_API_KEY\"))<25:\n",
        "    assert False, \"GROQ_API_KEY is required. Sign up and Get your API Key from https://console.groq.com/keys\"\n",
        "# print(os.getenv('REDDIT_NAME'))"
      ],
      "metadata": {
        "id": "Kmr4-w-t0_7j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GraphRAG Indexing\n",
        "!python -m graphrag.index --root ./ragtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RhpGz77fw3Qr",
        "outputId": "85a6856c-7b5f-4114-c35d-6875ef2cdac1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-06 03:30:29.196545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 03:30:29.229857: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 03:30:29.240018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 03:30:30.958087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K🚀 \u001b[32mReading settings from ragtest/settings.yaml\u001b[0m\n",
            "\u001b[2K⠴ GraphRAG Indexer \n",
            "\u001b[2K\u001b[1A\u001b[2K⠴ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠴ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠴ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠴ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: \n",
            "'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use \n",
            "'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "└── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K🚀 \u001b[32mcreate_base_text_units\u001b[0m\n",
            "⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K                                 id  \u001b[33m...\u001b[0m n_tokens\n",
            "\u001b[1;36m0\u001b[0m  68dbd5181ea19c6a93fcbedddb24afe3  \u001b[33m...\u001b[0m       \u001b[1;36m92\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m rows x \u001b[1;36m5\u001b[0m columns\u001b[1m]\u001b[0m\n",
            "⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠦ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠧ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠦ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠧ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠴ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠦ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "└── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K🚀 \u001b[32mcreate_base_extracted_entities\u001b[0m\n",
            "⠹ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K                                        entity_graph\n",
            "\u001b[1;36m0\u001b[0m  <graphml \u001b[33mxmlns\u001b[0m=\u001b[35m\"\u001b[0m\u001b[4;94mhttp\u001b[0m\u001b[4;94m://graphml.graphdrawing.or...\u001b[0m\n",
            "⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠧ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K🚀 \u001b[32mcreate_summarized_entities\u001b[0m\n",
            "⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K                                        entity_graph\n",
            "\u001b[1;36m0\u001b[0m  <graphml \u001b[33mxmlns\u001b[0m=\u001b[35m\"\u001b[0m\u001b[4;94mhttp\u001b[0m\u001b[4;94m://graphml.graphdrawing.or...\u001b[0m\n",
            "⠇ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠸ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K🚀 \u001b[32mcreate_base_entity_graph\u001b[0m\n",
            "⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K   level                                    clustered_graph\n",
            "\u001b[1;36m0\u001b[0m      \u001b[1;36m0\u001b[0m  <graphml \u001b[33mxmlns\u001b[0m=\u001b[35m\"\u001b[0m\u001b[4;94mhttp\u001b[0m\u001b[4;94m://graphml.graphdrawing.or...\u001b[0m\n",
            "⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠼ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: \n",
            "'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use \n",
            "'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "└── create_final_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠙ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "└── create_final_entities\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K❌ \u001b[31mcreate_final_entities\u001b[0m\n",
            "⠏ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[3;35mNone\u001b[0m\n",
            "⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K⠋ GraphRAG Indexer \n",
            "├── Loading Input (text) - 1 files loaded (0 filtered) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "├── create_base_text_units\n",
            "├── create_base_extracted_entities\n",
            "├── create_summarized_entities\n",
            "├── create_base_entity_graph\n",
            "└── create_final_entities\n",
            "\u001b[?25h❌ \u001b[31mErrors occurred during the pipeline run, see logs for more details.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNEkKJZBu8pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only global query?\n",
        "!python -m graphrag.query --root ./ragtest --method global \"Who is Marley?\""
      ],
      "metadata": {
        "id": "nJWyI8gVxB1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Local query\n",
        "# !python -m graphrag.query --root ./ragtest --method local \"Who is Marley?\""
      ],
      "metadata": {
        "id": "VvwgburwxNeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}